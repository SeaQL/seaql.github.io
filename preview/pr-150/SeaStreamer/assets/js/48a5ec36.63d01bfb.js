"use strict";(self.webpackChunksea_streamer=self.webpackChunksea_streamer||[]).push([[4986],{2465:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"streamer/consumer","title":"Consumer","description":"The Consumer trait defines the common interface of stream consumers.","source":"@site/versioned_docs/version-0.1.x/03-streamer/03-consumer.md","sourceDirName":"03-streamer","slug":"/streamer/consumer","permalink":"/preview/pr-150/SeaStreamer/docs/0.1.x/streamer/consumer","draft":false,"unlisted":false,"editUrl":"https://github.com/SeaQL/seaql.github.io/edit/master/SeaStreamer/versioned_docs/version-0.1.x/03-streamer/03-consumer.md","tags":[],"version":"0.1.x","lastUpdatedBy":"Chris Tsang","lastUpdatedAt":1755594254000,"sidebarPosition":3,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Producer","permalink":"/preview/pr-150/SeaStreamer/docs/0.1.x/streamer/producer"},"next":{"title":"Inter Process","permalink":"/preview/pr-150/SeaStreamer/docs/0.1.x/processors/inter-process"}}');var a=n(8790),t=n(6484);const r={},o="Consumer",c={},d=[{value:"<code>ConsumerOptions</code>",id:"consumeroptions",level:2},{value:"<code>ConsumerMode</code>",id:"consumermode",level:3},{value:"<code>RealTime</code>",id:"realtime",level:4},{value:"<code>Resumable</code>",id:"resumable",level:4},{value:"Kafka semantics",id:"kafka-semantics",level:4},{value:"<code>LoadBalanced</code>",id:"loadbalanced",level:4},{value:"<code>ConsumerGroup</code>",id:"consumergroup",level:3},{value:"Kafka semantics",id:"kafka-semantics-1",level:4},{value:"Stdio semantics",id:"stdio-semantics",level:4},{value:"<code>next</code>",id:"next",level:2},{value:"<code>stream</code>",id:"stream",level:2},{value:"<code>assign</code>",id:"assign",level:2},{value:"Kafka semantics",id:"kafka-semantics-2",level:4},{value:"Stdio semantics",id:"stdio-semantics-1",level:4},{value:"<code>rewind</code>",id:"rewind",level:2},{value:"Kafka semantics",id:"kafka-semantics-3",level:4},{value:"Stdio semantics",id:"stdio-semantics-2",level:4},{value:"<code>seek</code>",id:"seek",level:2},{value:"Kafka semantics",id:"kafka-semantics-4",level:4},{value:"Stdio semantics",id:"stdio-semantics-3",level:4}];function l(e){const s={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.header,{children:(0,a.jsx)(s.h1,{id:"consumer",children:"Consumer"})}),"\n",(0,a.jsxs)(s.p,{children:["The ",(0,a.jsx)(s.a,{href:"https://docs.rs/sea-streamer/*/sea_streamer/trait.Consumer.html",children:(0,a.jsx)(s.code,{children:"Consumer"})})," trait defines the common interface of stream consumers."]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.a,{href:"https://docs.rs/sea-streamer-kafka/*/sea_streamer_kafka/struct.KafkaConsumer.html",children:(0,a.jsx)(s.code,{children:"KafkaConsumer"})})," has more functions for committing offsets. ",(0,a.jsx)(s.a,{href:"https://docs.rs/sea-streamer-stdio/*/sea_streamer_stdio/struct.StdioConsumer.html",children:(0,a.jsx)(s.code,{children:"StdioConsumer"})})," currently has no specific functions."]}),"\n",(0,a.jsx)(s.h2,{id:"consumeroptions",children:(0,a.jsx)(s.code,{children:"ConsumerOptions"})}),"\n",(0,a.jsx)(s.h3,{id:"consumermode",children:(0,a.jsx)(s.code,{children:"ConsumerMode"})}),"\n",(0,a.jsx)(s.p,{children:"There are 3 modes:"}),"\n",(0,a.jsx)(s.h4,{id:"realtime",children:(0,a.jsx)(s.code,{children:"RealTime"})}),"\n",(0,a.jsx)(s.p,{children:"This is the 'vanilla' stream consumer. It does not auto-commit, and thus only consumes messages from now on."}),"\n",(0,a.jsx)(s.h4,{id:"resumable",children:(0,a.jsx)(s.code,{children:"Resumable"})}),"\n",(0,a.jsx)(s.p,{children:"When the process restarts, it will resume the stream from the previous committed sequence."}),"\n",(0,a.jsxs)(s.admonition,{type:"info",children:[(0,a.jsx)(s.h4,{id:"kafka-semantics",children:"Kafka semantics"}),(0,a.jsx)(s.p,{children:"It will use a group id unique to this host: on a physical machine, it will use the mac address.\nInside a docker container, it will use the container id."})]}),"\n",(0,a.jsx)(s.h4,{id:"loadbalanced",children:(0,a.jsx)(s.code,{children:"LoadBalanced"})}),"\n",(0,a.jsx)(s.p,{children:"You should assign a consumer group manually. The load-balancing mechanism is implementation-specific."}),"\n",(0,a.jsx)(s.h3,{id:"consumergroup",children:(0,a.jsx)(s.code,{children:"ConsumerGroup"})}),"\n",(0,a.jsx)(s.p,{children:"A consumer group is a string for clients to identify themselves to the streaming server. So that when you reconnect, the states can be downloaded from the server. From the broker's point of view, it is all that matters. The client can connect from any host or network."}),"\n",(0,a.jsx)(s.p,{children:"Multiple consumers can share the same consumer group, and remain connected to the server at the same time. Usually, the intention is to achieve load-balancing. The precise semantics is backend-specific."}),"\n",(0,a.jsxs)(s.admonition,{type:"info",children:[(0,a.jsx)(s.h4,{id:"kafka-semantics-1",children:"Kafka semantics"}),(0,a.jsx)(s.p,{children:"If multiple consumers shares the same group, only one consumer in the group will receive a message, i.e. it is load-balanced."}),(0,a.jsx)(s.p,{children:"However, the load-balancing mechanism is what makes Kafka different:"}),(0,a.jsx)(s.p,{children:"Each stream is divided into multiple shards (known as partition), and each partition will be assigned to only one consumer in a group."}),(0,a.jsx)(s.p,{children:"Say there are 2 consumers (in the group) and 2 partitions, then each consumer will receive messages from one partition, and they are thus load-balanced."}),(0,a.jsx)(s.p,{children:"If there are 2 consumers and 3 partitions, then one consumer will be assigned 2 partitions, and the other will be assigned only 1."}),(0,a.jsx)(s.p,{children:"However if the stream has only 1 partition, even if there are many consumers, these messages will only be received by the assigned consumer, and other consumers will be in stand-by mode, resulting in a hot-failover setup."})]}),"\n",(0,a.jsxs)(s.admonition,{type:"info",children:[(0,a.jsx)(s.h4,{id:"stdio-semantics",children:"Stdio semantics"}),(0,a.jsx)(s.p,{children:"If multiple consumers share the same group, only one in the group will receive a message.\nThis is load-balanced in a round-robin fashion."})]}),"\n",(0,a.jsx)(s.h2,{id:"next",children:(0,a.jsx)(s.code,{children:"next"})}),"\n",(0,a.jsx)(s.p,{children:"Poll and receive one message: it awaits until there are new messages."}),"\n",(0,a.jsx)(s.h2,{id:"stream",children:(0,a.jsx)(s.code,{children:"stream"})}),"\n",(0,a.jsx)(s.p,{children:"Returns an async stream. You cannot create multiple streams from the same consumer, nor perform any operation while streaming."}),"\n",(0,a.jsx)(s.p,{children:"It allows you to do neat things:"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-rust",children:"let items = consumer\n    .stream()\n    .take(num)\n    .map(process_message)\n    .collect::<Vec<_>>()\n    .await\n"})}),"\n",(0,a.jsx)(s.h2,{id:"assign",children:(0,a.jsx)(s.code,{children:"assign"})}),"\n",(0,a.jsx)(s.p,{children:"Assign this consumer to a particular shard."}),"\n",(0,a.jsxs)(s.p,{children:["It will only take effect on the next ",(0,a.jsx)(s.code,{children:"Consumer::seek"})," or ",(0,a.jsx)(s.code,{children:"Consumer::rewind"}),"."]}),"\n",(0,a.jsxs)(s.admonition,{type:"info",children:[(0,a.jsx)(s.h4,{id:"kafka-semantics-2",children:"Kafka semantics"}),(0,a.jsxs)(s.p,{children:["Always succeed. This operation is additive. You can assign a consumer to multiple shards (aka partition). There is also a ",(0,a.jsx)(s.code,{children:"KafkaConsumer::unassign"})," method."]})]}),"\n",(0,a.jsxs)(s.admonition,{type:"info",children:[(0,a.jsx)(s.h4,{id:"stdio-semantics-1",children:"Stdio semantics"}),(0,a.jsx)(s.p,{children:"There is only shard ZERO anyway."})]}),"\n",(0,a.jsx)(s.h2,{id:"rewind",children:(0,a.jsx)(s.code,{children:"rewind"})}),"\n",(0,a.jsx)(s.p,{children:"Rewind the stream to a particular sequence number."}),"\n",(0,a.jsx)(s.p,{children:"If the consumer is not already assigned, shard ZERO will be used."}),"\n",(0,a.jsxs)(s.admonition,{type:"info",children:[(0,a.jsx)(s.h4,{id:"kafka-semantics-3",children:"Kafka semantics"}),(0,a.jsx)(s.p,{children:"Note: this rewind all streams across all assigned partitions."})]}),"\n",(0,a.jsxs)(s.admonition,{type:"caution",children:[(0,a.jsx)(s.h4,{id:"stdio-semantics-2",children:"Stdio semantics"}),(0,a.jsx)(s.p,{children:"This is not implemented by the Stdio backend."})]}),"\n",(0,a.jsx)(s.h2,{id:"seek",children:(0,a.jsx)(s.code,{children:"seek"})}),"\n",(0,a.jsxs)(s.p,{children:["Seek all streams to the given point in time. It will start consuming from the earliest message with a timestamp later than ",(0,a.jsx)(s.code,{children:"to"}),"."]}),"\n",(0,a.jsx)(s.p,{children:"If the consumer is not already assigned, shard ZERO will be used."}),"\n",(0,a.jsxs)(s.admonition,{type:"info",children:[(0,a.jsx)(s.h4,{id:"kafka-semantics-4",children:"Kafka semantics"}),(0,a.jsx)(s.p,{children:"This async method is not cancel safe. You must await this future, and this Consumer will be unusable for any operations until it finishes."})]}),"\n",(0,a.jsxs)(s.admonition,{type:"caution",children:[(0,a.jsx)(s.h4,{id:"stdio-semantics-3",children:"Stdio semantics"}),(0,a.jsx)(s.p,{children:"This is not implemented by the Stdio backend."})]})]})}function m(e={}){const{wrapper:s}={...(0,t.R)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},6484:(e,s,n)=>{n.d(s,{R:()=>r,x:()=>o});var i=n(2374);const a={},t=i.createContext(a);function r(e){const s=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(t.Provider,{value:s},e.children)}}}]);